hidden layer:2*2
Starting training...

--- Epoch 0 ---
Loss: 0.748230
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5446,  0.5913],
        [-0.1721,  0.6415]], requires_grad=True)
Weight Norm (L2/Fro): 1.0428
Hidden Bias (fc1.bias): Parameter containing:   
tensor([-0.1435,  0.1265], requires_grad=True)  
Weight Gradient (fc1.weight.grad):
tensor([[-0.0040, -0.0044],
        [ 0.0064,  0.0081]])
Gradient Norm (L2/Fro): 0.0119

--- Epoch 1000 ---
Loss: 0.691658                          # loss is not decreasing, model is not learning, no emergence yet
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[0.3500, 0.4035],
        [0.4143, 0.7594]], requires_grad=True)
Weight Norm (L2/Fro): 1.0167
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.7583,  0.1508], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0007, -0.0007],
        [-0.0030, -0.0017]])
Gradient Norm (L2/Fro): 0.0036

--- Epoch 2000 ---
Loss: 0.015252                          # loss is decreasing, model is learning, emergence is happening
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[4.7714, 4.7717],
        [6.4362, 6.4374]], requires_grad=True)
Hidden Bias (fc1.bias): Parameter containing:
tensor([-7.3086, -2.8475], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0010, -0.0010],
        [-0.0009, -0.0009]])
Gradient Norm (L2/Fro): 0.0018           # gradient is decreasing, model is converging

--- Epoch 3000 ---
Loss: 0.005931
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[5.3261, 5.3262],
        [6.9573, 6.9580]], requires_grad=True)
Weight Norm (L2/Fro): 12.3917
Hidden Bias (fc1.bias): Parameter containing:
tensor([-8.1517, -3.1479], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0003, -0.0003],
        [-0.0003, -0.0003]])
Gradient Norm (L2/Fro): 0.0007             # gradient is very small, model is close to convergence

--- Epoch 4000 ---
Loss: 0.003650
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[5.5857, 5.5859],
        [7.2071, 7.2076]], requires_grad=True)
Weight Norm (L2/Fro): 12.8955
Hidden Bias (fc1.bias): Parameter containing:
tensor([-8.5443, -3.2860], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0002, -0.0002],
        [-0.0002, -0.0002]])
Gradient Norm (L2/Fro): 0.0004

--- Epoch 5000 ---
Loss: 0.002629
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[5.7529, 5.7530],
        [7.3693, 7.3697]], requires_grad=True)
Weight Norm (L2/Fro): 13.2217
Hidden Bias (fc1.bias): Parameter containing:
tensor([-8.7964, -3.3742], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0001, -0.0001],
        [-0.0001, -0.0001]])
Gradient Norm (L2/Fro): 0.0003

--- Epoch 6000 ---
Loss: 0.002052
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[5.8751, 5.8752],
        [7.4886, 7.4890]], requires_grad=True)
Weight Norm (L2/Fro): 13.4610
Hidden Bias (fc1.bias): Parameter containing:
tensor([-8.9806, -3.4385], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0001, -0.0001],
        [-0.0001, -0.0001]])
Gradient Norm (L2/Fro): 0.0002

--- Epoch 7000 ---
Loss: 0.001682
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[5.9709, 5.9710],
        [7.5824, 7.5828]], requires_grad=True)
Weight Norm (L2/Fro): 13.6490
Hidden Bias (fc1.bias): Parameter containing:
tensor([-9.1248, -3.4887], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-8.6076e-05, -8.6062e-05],
        [-8.4437e-05, -8.4409e-05]])
Gradient Norm (L2/Fro): 0.0002

--- Epoch 8000 ---
Loss: 0.001424
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[6.0494, 6.0495],
        [7.6595, 7.6598]], requires_grad=True)
Weight Norm (L2/Fro): 13.8034
Hidden Bias (fc1.bias): Parameter containing:
tensor([-9.2429, -3.5297], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-7.1777e-05, -7.1766e-05],
        [-7.0566e-05, -7.0545e-05]])
Gradient Norm (L2/Fro): 0.0001

--- Epoch 9000 ---
Loss: 0.001234
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[6.1158, 6.1158],
        [7.7248, 7.7251]], requires_grad=True)
Weight Norm (L2/Fro): 13.9340
Hidden Bias (fc1.bias): Parameter containing:
tensor([-9.3427, -3.5643], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-6.1427e-05, -6.1419e-05],
        [-6.0480e-05, -6.0462e-05]])
Gradient Norm (L2/Fro): 0.0001

--- Epoch 9999 ---
Loss: 0.001089
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[6.1730, 6.1731],
        [7.7812, 7.7815]], requires_grad=True)
Weight Norm (L2/Fro): 14.0468
Hidden Bias (fc1.bias): Parameter containing:
        [7.7812, 7.7815]], requires_grad=True)
Weight Norm (L2/Fro): 14.0468
Hidden Bias (fc1.bias): Parameter containing:
tensor([-9.4288, -3.5942], requires_grad=True)
Weight Gradient (fc1.weight.grad):
Weight Norm (L2/Fro): 14.0468
Hidden Bias (fc1.bias): Parameter containing:
tensor([-9.4288, -3.5942], requires_grad=True)
Weight Gradient (fc1.weight.grad):
Hidden Bias (fc1.bias): Parameter containing:
tensor([-9.4288, -3.5942], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-5.3585e-05, -5.3594e-05],
tensor([-9.4288, -3.5942], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-5.3585e-05, -5.3594e-05],
Weight Gradient (fc1.weight.grad):
tensor([[-5.3585e-05, -5.3594e-05],
        [-5.2847e-05, -5.2827e-05]])
Gradient Norm (L2/Fro): 0.0001
tensor([[-5.3585e-05, -5.3594e-05],
        [-5.2847e-05, -5.2827e-05]])
Gradient Norm (L2/Fro): 0.0001
        [-5.2847e-05, -5.2827e-05]])
Gradient Norm (L2/Fro): 0.0001
Gradient Norm (L2/Fro): 0.0001


Decision boundary plot saved as 'e:\LLM\Emergence_Generalization\xor_decision_boundary.png'.

Final Predictions:
Input: [0.0, 0.0] → Target: 0, Prediction: 0.0014
Input: [0.0, 1.0] → Target: 1, Prediction: 0.9990
Input: [1.0, 0.0] → Target: 1, Prediction: 0.9990
Input: [1.0, 1.0] → Target: 0, Prediction: 0.0010
✅ Model saved in safetensors format at 'e:\LLM\Emergence_Generalization\xor_model.safetensors'.

=== Final Hidden Layer Parameters ===
fc1.weight:
 Parameter containing:
tensor([[6.1730, 6.1731],
        [7.7812, 7.7815]], requires_grad=True)
fc1.bias:  Parameter containing:
tensor([-9.4288, -3.5942], requires_grad=True)
Weight L2 Norm:  14.046817779541016

------------------------------------------------------------------------------------------------------------------
hidden layer:2*6
Starting training...

--- Epoch 0 ---
Loss: 0.721282
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5375,  0.5839],
        [-0.1639,  0.6507],
        [-0.1577,  0.1403],
        [-0.3449,  0.4146],
        [ 0.6223, -0.5215],
        [ 0.6184,  0.1372]], requires_grad=True)
Weight Norm (L2/Fro): 1.5735
Hidden Bias (fc1.bias): Parameter containing:
tensor([ 0.5181,  0.0985,  0.3357, -0.1011,  0.5414,  0.1121],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 0.0031,  0.0030],
        [-0.0017, -0.0012],
        [ 0.0028,  0.0024],
        [ 0.0006,  0.0006],
        [ 0.0010,  0.0028],
        [-0.0037, -0.0048]])
Gradient Norm (L2/Fro): 0.0091

--- Epoch 100 ---
Loss: 0.690503
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5808,  0.6194],
        [-0.1353,  0.6201],
        [-0.1596,  0.1630],
        [-0.3484,  0.4116],
        [ 0.7581, -0.5755],
        [ 0.7010,  0.3272]], requires_grad=True)
Weight Norm (L2/Fro): 1.7237
Hidden Bias (fc1.bias): Parameter containing:
tensor([ 0.5267,  0.0831,  0.3386, -0.1049,  0.6174,  0.1791],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-1.4808e-03, -1.2104e-03],
        [-1.5972e-04,  2.1775e-04],
        [ 2.2677e-05, -3.2191e-04],
        [ 1.6341e-05,  1.8577e-05],
        [-2.4923e-03,  1.0411e-03],
        [-1.4521e-03, -2.4685e-03]])
Gradient Norm (L2/Fro): 0.0044

--- Epoch 200 ---
Loss: 0.675174
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.9102,  0.8820],
        [-0.1360,  0.6246],
        [-0.1644,  0.2180],
        [-0.3438,  0.4207],
        [ 1.2502, -0.8378],
        [ 1.0094,  0.7205]], requires_grad=True)
Weight Norm (L2/Fro): 2.4875
Hidden Bias (fc1.bias): Parameter containing:
tensor([ 0.5764,  0.0830,  0.3438, -0.1000,  0.8732,  0.3271],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0058, -0.0045],
        [ 0.0002, -0.0006],
        [ 0.0001, -0.0010],
        [-0.0001, -0.0004],
        [-0.0086,  0.0054],
        [-0.0057, -0.0061]])
Gradient Norm (L2/Fro): 0.0151

--- Epoch 300 ---
Loss: 0.541961
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 1.8824,  1.5768],
        [-0.2623,  0.9679],
        [-0.2171,  0.4828],
        [-0.3243,  0.6401],
        [ 2.8008, -1.9843],
        [ 2.0284,  1.6063]], requires_grad=True)
Weight Norm (L2/Fro): 5.1291
Hidden Bias (fc1.bias): Parameter containing:
tensor([ 0.4636,  0.0855,  0.3396, -0.0595,  1.4690,  0.3270],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-1.3052e-02, -8.4750e-03],
        [ 3.5641e-03, -9.3211e-03],
        [ 1.4494e-03, -5.7355e-03],
        [ 2.5837e-05, -6.1666e-03],
        [-2.0944e-02,  1.5978e-02],
        [-1.3960e-02, -1.0346e-02]])
Gradient Norm (L2/Fro): 0.0376

--- Epoch 400 ---
Loss: 0.234450
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 3.0089,  2.4410],
        [-0.9721,  2.6765],
        [-0.4614,  1.3745],
        [-0.4600,  1.7490],
        [ 4.6165, -3.4062],
        [ 3.2283,  2.6106]], requires_grad=True)
Weight Norm (L2/Fro): 8.8682
Hidden Bias (fc1.bias): Parameter containing:
tensor([ 0.1156, -0.0058,  0.1646, -0.1285,  1.8058, -0.0606],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0076, -0.0081],
        [ 0.0081, -0.0178],
        [ 0.0021, -0.0088],
        [ 0.0022, -0.0112],
        [-0.0137,  0.0110],
        [-0.0080, -0.0090]])
Gradient Norm (L2/Fro): 0.0342

--- Epoch 500 ---
Loss: 0.093257                        #loss is decreasing, model is learning, emergence is happening
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 3.4907,  3.0435],
        [-1.6020,  3.8915],
        [-0.5816,  2.0041],
        [-0.6239,  2.5466],
        [ 5.5721, -4.1383],
        [ 3.7360,  3.2660]], requires_grad=True)
Weight Norm (L2/Fro): 11.0989
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.0749,  0.1332,  0.0055, -0.2673,  1.8897, -0.2741],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0030, -0.0042],
        [ 0.0046, -0.0079],
        [ 0.0007, -0.0044],
        [ 0.0012, -0.0055],
        [-0.0065,  0.0047],
        [-0.0032, -0.0045]])
Gradient Norm (L2/Fro): 0.0161

--- Epoch 600 ---
Loss: 0.052059
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 3.7138,  3.3613],
        [-1.9580,  4.4714],
        [-0.6322,  2.3391],
        [-0.7207,  2.9698],
        [ 6.0641, -4.4826],
        [ 3.9688,  3.6024]], requires_grad=True)
Weight Norm (L2/Fro): 12.2362
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.1537,  0.2460, -0.0867, -0.3445,  1.9357, -0.3607],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0017, -0.0024],
        [ 0.0027, -0.0043],
        [ 0.0004, -0.0026],
        [ 0.0008, -0.0033],
        [-0.0038,  0.0026],
        [-0.0017, -0.0025]])
Gradient Norm (L2/Fro): 0.0091                  # gradient is decreasing, model is converging

--- Epoch 700 ---
Loss: 0.035012
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 3.8478,  3.5569],
        [-2.1823,  4.8160],
        [-0.6643,  2.5546],
        [-0.7878,  3.2410],
        [ 6.3707, -4.6885],
        [ 4.1077,  3.8069]], requires_grad=True)
Weight Norm (L2/Fro): 12.9398
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.1956,  0.3209, -0.1502, -0.3938,  1.9636, -0.4063],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0011, -0.0016],
        [ 0.0018, -0.0028],
        [ 0.0003, -0.0018],
        [ 0.0006, -0.0023],
        [-0.0025,  0.0017],
        [-0.0011, -0.0017]])
Gradient Norm (L2/Fro): 0.0061

--- Epoch 800 ---
Loss: 0.026055
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 3.9407,  3.6933],
        [-2.3403,  5.0523],
        [-0.6879,  2.7109],
        [-0.8387,  3.4366],
        [ 6.5871, -4.8307],
        [ 4.2036,  3.9485]], requires_grad=True)
Weight Norm (L2/Fro): 13.4349
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.2224,  0.3745, -0.1980, -0.4287,  1.9827, -0.4352],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0008, -0.0012],
        [ 0.0014, -0.0020],
        [ 0.0002, -0.0014],
        [ 0.0005, -0.0017],
        [-0.0019,  0.0012],
        [-0.0008, -0.0012]])
Gradient Norm (L2/Fro): 0.0045

--- Epoch 900 ---
Loss: 0.020623
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 4.0108,  3.7962],
        [-2.4601,  5.2287],
        [-0.7065,  2.8327],
        [-0.8797,  3.5881],
        [ 6.7521, -4.9375],
        [ 4.2758,  4.0549]], requires_grad=True)
Weight Norm (L2/Fro): 13.8114
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.2415,  0.4154, -0.2361, -0.4553,  1.9970, -0.4557],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0006, -0.0009],
        [ 0.0011, -0.0016],
        [ 0.0002, -0.0011],
        [ 0.0004, -0.0014],
        [-0.0015,  0.0009],
        [-0.0006, -0.0009]])
Gradient Norm (L2/Fro): 0.0035

--- Epoch 999 ---
Loss: 0.017037
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 4.0661,  3.8773],
        [-2.5547,  5.3667],
        [-0.7218,  2.9312],
        [-0.9135,  3.7100],
        [ 6.8831, -5.0215],
        [ 4.3326,  4.1384]], requires_grad=True)
Weight Norm (L2/Fro): 14.1101
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.2558,  0.4477, -0.2673, -0.4762,  2.0081, -0.4710],
       requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0005, -0.0007],
        [ 0.0009, -0.0013],
        [ 0.0001, -0.0009],
        [ 0.0003, -0.0011],
        [-0.0012,  0.0008],
        [-0.0005, -0.0008]])
Gradient Norm (L2/Fro): 0.0029

Decision boundary plot saved as 'e:\LLM\Emergence_Generalization\XORNet\xor_decision_boundary.png'.

Final Predictions:
Input: [0.0, 0.0] → Target: 0, Prediction: 0.0038
Input: [0.0, 1.0] → Target: 1, Prediction: 0.9801
Input: [1.0, 0.0] → Target: 1, Prediction: 0.9835
Input: [1.0, 1.0] → Target: 0, Prediction: 0.0272
✅ Model saved in safetensors format at 'e:\LLM\Emergence_Generalization\XORNet\xor_model.safetensors'.

=== Final Hidden Layer Parameters ===
fc1.weight:
 Parameter containing:
tensor([[ 4.0661,  3.8773],
        [-2.5547,  5.3667],
        [-0.7218,  2.9312],
        [-0.9135,  3.7100],
        [ 6.8831, -5.0215],
        [ 4.3326,  4.1384]], requires_grad=True)
fc1.bias:  Parameter containing:
tensor([-0.2558,  0.4477, -0.2673, -0.4762,  2.0081, -0.4710],
       requires_grad=True)
Weight L2 Norm:  14.11008071899414


------------------------------------------------------------------------------------------------------------------
hidden layer:2*12
Starting training...

--- Epoch 0 ---
Loss: 0.737886 
Hidden Weight (fc1.weight):
Parameter containing:      
tensor([[ 0.5399,  0.5862],
        [-0.1703,  0.6451],
        [-0.1555,  0.1421],
        [-0.3424,  0.4168],
        [ 0.6217, -0.5203],
        [ 0.6161,  0.1339],
        [ 0.5209,  0.0947],
        [ 0.3363, -0.1049],
        [ 0.5430,  0.1030],
        [-0.3277,  0.1826],
        [-0.3286, -0.0855],
        [-0.2880,  0.4681]], requires_grad=True)
Weight Norm (L2/Fro): 1.9335
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.5595, -0.3346, -0.2008, -0.4218,  0.0637, -0.6957,  0.6351, -0.6096,
         0.5410,  0.1224, -0.2353,  0.4351], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 0.0007,  0.0007],
        [ 0.0047,  0.0044],
        [ 0.0006,  0.0006],
        [-0.0019, -0.0016],
        [ 0.0016,  0.0015],
        [-0.0015, -0.0016],
        [ 0.0015,  0.0011],
        [ 0.0047,  0.0051],
        [ 0.0021,  0.0015],
        [-0.0024, -0.0024],
        [ 0.0028,  0.0025],
        [ 0.0008,  0.0010]])
Gradient Norm (L2/Fro): 0.0120

--- Epoch 60 ---
Loss: 0.692803
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5365,  0.5822],
        [-0.1930,  0.6410],
        [-0.1542,  0.1412],
        [-0.3184,  0.4092],
        [ 0.6262, -0.5187],
        [ 0.6183,  0.1534],
        [ 0.5231,  0.1069],
        [ 0.3412, -0.1361],
        [ 0.5492,  0.1336],
        [-0.3216,  0.1892],
        [-0.3257, -0.0697],
        [-0.2972,  0.4784]], requires_grad=True)
Weight Norm (L2/Fro): 1.9394
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.5671, -0.3527, -0.2003, -0.4091,  0.0699, -0.7069,  0.6357, -0.6158,
         0.5432,  0.1332, -0.2331,  0.4413], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 5.8474e-05,  6.7456e-05],
        [ 4.2770e-04,  8.0901e-05],
        [-1.9296e-05,  1.1456e-05],
        [-3.0350e-04,  8.7755e-05],
        [-1.5544e-04, -5.2419e-05],
        [-3.4770e-05, -3.6021e-04],
        [-5.5057e-05, -2.8718e-04],
        [-1.1230e-04,  5.6393e-04],
        [-1.4630e-04, -6.2011e-04],
        [-8.8437e-05, -1.2973e-04],
        [-4.3218e-05, -2.4211e-04],
        [ 2.2557e-04, -2.5412e-04]])
Gradient Norm (L2/Fro): 0.0012

--- Epoch 120 ---
Loss: 0.692414
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5327,  0.5779],
        [-0.2226,  0.6358],
        [-0.1532,  0.1407],
        [-0.3049,  0.4055],
        [ 0.6409, -0.5143],
        [ 0.6203,  0.1771],
        [ 0.5282,  0.1303],
        [ 0.3501, -0.1732],
        [ 0.5623,  0.1802],
        [-0.3169,  0.1980],
        [-0.3234, -0.0562],
        [-0.3162,  0.5001]], requires_grad=True)
Weight Norm (L2/Fro): 1.9642
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.5756, -0.3758, -0.1999, -0.4016,  0.0900, -0.7223,  0.6370, -0.6245,
         0.5472,  0.1446, -0.2315,  0.4539], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 6.8513e-05,  7.5985e-05],
        [ 5.6712e-04,  9.0986e-05],
        [-1.4719e-05,  8.0321e-06],
        [-1.5747e-04,  4.0396e-05],
        [-3.4099e-04, -8.9337e-05],
        [-3.3651e-05, -4.2913e-04],
        [-1.2075e-04, -4.9900e-04],
        [-1.8703e-04,  6.7677e-04],
        [-3.0594e-04, -9.5246e-04],
        [-7.0178e-05, -1.6247e-04],
        [-3.3071e-05, -2.1187e-04],
        [ 4.1457e-04, -4.7922e-04]])
Gradient Norm (L2/Fro): 0.0017

--- Epoch 180 ---
Loss: 0.691716
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5282,  0.5729],
        [-0.2627,  0.6305],
        [-0.1523,  0.1402],
        [-0.2991,  0.4041],
        [ 0.6691, -0.5090],
        [ 0.6227,  0.2051],
        [ 0.5388,  0.1686],
        [ 0.3642, -0.2184],
        [ 0.5897,  0.2527],
        [-0.3130,  0.2088],
        [-0.3218, -0.0442],
        [-0.3488,  0.5387]], requires_grad=True)
Weight Norm (L2/Fro): 2.0188
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.5863, -0.4054, -0.1995, -0.3983,  0.1261, -0.7434,  0.6394, -0.6366,
         0.5544,  0.1567, -0.2305,  0.4763], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 8.4513e-05,  9.3082e-05],
        [ 7.8335e-04,  8.3718e-05],
        [-1.2776e-05,  6.0982e-06],
        [-4.1620e-05,  9.6905e-06],
        [-6.1773e-04, -7.3781e-05],
        [-4.6313e-05, -5.0754e-04],
        [-2.4438e-04, -7.9041e-04],
        [-2.8560e-04,  8.4143e-04],
        [-6.4624e-04, -1.5098e-03],
        [-6.1552e-05, -1.9837e-04],
        [-2.1244e-05, -1.8705e-04],
        [ 6.8795e-04, -8.3339e-04]])
Gradient Norm (L2/Fro): 0.0026

--- Epoch 240 ---
Loss: 0.690191
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5225,  0.5666],
        [-0.3196,  0.6264],
        [-0.1516,  0.1399],
        [-0.2998,  0.4042],
        [ 0.7197, -0.5082],
        [ 0.6265,  0.2387],
        [ 0.5600,  0.2282],
        [ 0.3854, -0.2762],
        [ 0.6489,  0.3715],
        [-0.3093,  0.2221],
        [-0.3209, -0.0337],
        [-0.4027,  0.6062]], requires_grad=True)
Weight Norm (L2/Fro): 2.1303
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.6011, -0.4448, -0.1991, -0.3987,  0.1844, -0.7726,  0.6436, -0.6541,
         0.5673,  0.1701, -0.2298,  0.5153], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 1.0358e-04,  1.1707e-04],
        [ 1.1402e-03,  4.2869e-05],
        [-1.3545e-05,  4.6763e-06],
        [ 6.4000e-05, -1.3153e-05],
        [-1.1105e-03,  7.9629e-05],
        [-8.8719e-05, -6.1641e-04],
        [-4.8439e-04, -1.2194e-03],
        [-4.2763e-04,  1.0998e-03],
        [-1.4272e-03, -2.5475e-03],
        [-6.4892e-05, -2.4823e-04],
        [-6.7500e-06, -1.6358e-04],
        [ 1.1453e-03, -1.4776e-03]])
Gradient Norm (L2/Fro): 0.0043

--- Epoch 300 ---
Loss: 0.685972
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5160,  0.5588],
        [-0.4057,  0.6270],
        [-0.1506,  0.1397],
        [-0.3070,  0.4055],
        [ 0.8135, -0.5264],
        [ 0.6349,  0.2808],
        [ 0.6018,  0.3202],
        [ 0.4171, -0.3544],
        [ 0.7847,  0.5825],
        [-0.3046,  0.2394],
        [-0.3211, -0.0247],
        [-0.4963,  0.7316]], requires_grad=True)
Weight Norm (L2/Fro): 2.3691
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.6224, -0.5003, -0.1987, -0.4027,  0.2781, -0.8129,  0.6510, -0.6804,
         0.5863,  0.1854, -0.2295,  0.5870], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 1.0836e-04,  1.3684e-04],
        [ 1.7891e-03, -8.2776e-05],
        [-2.0150e-05,  1.9915e-06],
        [ 1.7669e-04, -2.6649e-05],
        [-2.1419e-03,  6.2322e-04],
        [-2.1300e-04, -8.0575e-04],
        [-9.5297e-04, -1.8875e-03],
        [-6.3810e-04,  1.5423e-03],
        [-3.3600e-03, -4.7344e-03],
        [-9.8835e-05, -3.3594e-04],
        [ 1.5788e-05, -1.3590e-04],
        [ 2.0920e-03, -2.8800e-03]])
Gradient Norm (L2/Fro): 0.0079

--- Epoch 360 ---
Loss: 0.670191
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5115,  0.5513],
        [-0.5489,  0.6417],
        [-0.1488,  0.1399],
        [-0.3220,  0.4069],
        [ 1.0093, -0.6086],
        [ 0.6574,  0.3398],
        [ 0.6830,  0.4633],
        [ 0.4640, -0.4695],
        [ 1.1089,  0.9933],
        [-0.2955,  0.2644],
        [-0.3233, -0.0177],
        [-0.6869,  0.9984]], requires_grad=True)
Weight Norm (L2/Fro): 2.9309
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.6550, -0.5835, -0.1981, -0.4101,  0.4381, -0.8711,  0.6633, -0.7218,
         0.5739,  0.2036, -0.2295,  0.7308], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[ 5.7467e-06,  9.1902e-05],
        [ 3.1427e-03, -4.7565e-04],
        [-4.5366e-05, -9.9090e-06],
        [ 3.3347e-04, -1.2148e-05],
        [-4.7875e-03,  2.4622e-03],
        [-6.0543e-04, -1.2123e-03],
        [-1.8188e-03, -2.9418e-03],
        [-9.3267e-04,  2.3706e-03],
        [-7.9496e-03, -9.4140e-03],
        [-2.3272e-04, -5.1848e-04],
        [ 6.4750e-05, -9.6290e-05],
        [ 4.7073e-03, -6.5803e-03]])
Gradient Norm (L2/Fro): 0.0166

--- Epoch 420 ---
Loss: 0.596063
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.5268,  0.5551],
        [-0.8241,  0.7025],
        [-0.1446,  0.1414],
        [-0.3520,  0.4047],
        [ 1.4909, -0.9124],
        [ 0.7282,  0.4401],
        [ 0.8287,  0.6821],
        [ 0.5278, -0.6568],
        [ 1.8076,  1.7762],
        [-0.2701,  0.3057],
        [-0.3319, -0.0141],
        [-1.1748,  1.6514]], requires_grad=True)
Weight Norm (L2/Fro): 4.3052
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.7085, -0.7088, -0.1975, -0.4207,  0.7156, -0.9665,  0.6881, -0.7834,
         0.2853,  0.2221, -0.2287,  1.0092], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-6.9992e-04, -3.4562e-04],
        [ 6.5075e-03, -1.7638e-03],
        [-7.9806e-05, -3.8295e-05],
        [ 7.5739e-04,  1.2948e-04],
        [-1.2354e-02,  8.6425e-03],
        [-2.0532e-03, -2.3243e-03],
        [-3.0041e-03, -4.3086e-03],
        [-1.1140e-03,  4.0536e-03],
        [-1.5438e-02, -1.6772e-02],
        [-6.8266e-04, -8.8932e-04],
        [ 2.8782e-04,  2.4037e-06],
        [ 1.2588e-02, -1.6297e-02]])
Gradient Norm (L2/Fro): 0.0357

--- Epoch 480 ---
Loss: 0.362976
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.6233,  0.6179],
        [-1.3787,  0.8879],
        [-0.1511,  0.1369],
        [-0.4325,  0.3791],
        [ 2.5431, -1.6800],
        [ 0.9382,  0.6475],
        [ 1.0209,  0.9472],
        [ 0.5902, -0.9708],
        [ 2.8348,  2.8677],
        [-0.2184,  0.3645],
        [-0.3775, -0.0301],
        [-2.1578,  2.9312]], requires_grad=True)
Weight Norm (L2/Fro): 6.8908
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.8083, -0.8206, -0.1962, -0.4268,  1.0063, -1.1618,  0.7749, -0.8275,
        -0.3357,  0.2243, -0.2147,  1.3101], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-0.0023, -0.0018],
        [ 0.0112, -0.0045],
        [ 0.0004,  0.0003],
        [ 0.0019,  0.0008],
        [-0.0203,  0.0148],
        [-0.0045, -0.0044],
        [-0.0031, -0.0040],
        [-0.0012,  0.0061],
        [-0.0162, -0.0167],
        [-0.0008, -0.0008],
        [ 0.0013,  0.0006],
        [ 0.0173, -0.0230]])
Gradient Norm (L2/Fro): 0.0476

--- Epoch 540 ---
Loss: 0.163096
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.7509,  0.7336],
        [-2.0058,  1.1823],
        [-0.1903,  0.1040],
        [-0.5487,  0.3243],
        [ 3.5561, -2.4157],
        [ 1.1660,  0.9047],
        [ 1.1840,  1.1357],
        [ 0.6942, -1.3150],
        [ 3.5721,  3.6008],
        [-0.1965,  0.3911],
        [-0.4606, -0.0821],
        [-2.9898,  4.0363]], requires_grad=True)
Weight Norm (L2/Fro): 9.1600
Hidden Bias (fc1.bias): Parameter containing:
tensor([-0.9485, -0.8410, -0.1849, -0.4152,  1.2058, -1.4631,  0.8914, -0.7945,
        -0.7195,  0.2190, -0.1705,  1.5058], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-1.6922e-03, -1.8305e-03],
        [ 8.9358e-03, -4.7331e-03],
        [ 7.1130e-04,  6.7392e-04],
        [ 1.7143e-03,  8.8583e-04],
        [-1.2667e-02,  9.3460e-03],
        [-2.9155e-03, -3.8603e-03],
        [-2.2446e-03, -2.3372e-03],
        [-2.0961e-03,  5.1137e-03],
        [-8.8190e-03, -8.4367e-03],
        [-9.1676e-05, -1.2994e-04],
        [ 1.2383e-03,  9.2320e-04],
        [ 1.0340e-02, -1.3551e-02]])
Gradient Norm (L2/Fro): 0.0295

--- Epoch 599 ---
Loss: 0.085988
Hidden Weight (fc1.weight):
Parameter containing:
tensor([[ 0.8275,  0.8257],
        [-2.4355,  1.4255],
        [-0.2275,  0.0659],
        [-0.6310,  0.2808],
        [ 4.1113, -2.8371],
        [ 1.2999,  1.0990],
        [ 1.2909,  1.2419],
        [ 0.8164, -1.5738],
        [ 3.9605,  3.9668],
        [-0.1968,  0.3905],
        [-0.5189, -0.1302],
        [-3.4508,  4.6287]], requires_grad=True)
Weight Norm (L2/Fro): 10.4545
Hidden Bias (fc1.bias): Parameter containing:
tensor([-1.0665, -0.8581, -0.1699, -0.3978,  1.3480, -1.7216,  0.9590, -0.7473,
        -0.9275,  0.2192, -0.1230,  1.6407], requires_grad=True)
Weight Gradient (fc1.weight.grad):
tensor([[-9.9770e-04, -1.3132e-03],
        [ 5.8995e-03, -3.5429e-03],
        [ 5.4290e-04,  5.9055e-04],
        [ 1.1248e-03,  5.9790e-04],
        [-6.9754e-03,  5.4728e-03],
        [-1.7995e-03, -2.7926e-03],
        [-1.4562e-03, -1.3975e-03],
        [-1.9511e-03,  3.7524e-03],
        [-4.9387e-03, -4.6016e-03],
        [ 5.6692e-05,  9.2322e-05],
        [ 7.7700e-04,  6.9848e-04],
        [ 5.9176e-03, -7.4298e-03]])
Gradient Norm (L2/Fro): 0.0173

Decision boundary plot saved as 'e:\LLM\Emergence_Generalization\XORNet\xor_decision_boundary.png'.

Final Predictions:
Input: [0.0, 0.0] → Target: 0, Prediction: 0.0459
Input: [0.0, 1.0] → Target: 1, Prediction: 0.9184
Input: [1.0, 0.0] → Target: 1, Prediction: 0.9131
Input: [1.0, 1.0] → Target: 0, Prediction: 0.1112
✅ Model saved in safetensors format at 'e:\LLM\Emergence_Generalization\XORNet\xor_model.safetensors'.

=== Final Hidden Layer Parameters ===
fc1.weight:
 Parameter containing:
tensor([[ 0.8275,  0.8257],
        [-2.4355,  1.4255],
        [-0.2275,  0.0659],
        [-0.6310,  0.2808],
        [ 4.1113, -2.8371],
        [ 1.2999,  1.0990],
        [ 1.2909,  1.2419],
        [ 0.8164, -1.5738],
        [ 3.9605,  3.9668],
        [-0.1968,  0.3905],
        [-0.5189, -0.1302],
        [-3.4508,  4.6287]], requires_grad=True)
fc1.bias:  Parameter containing:
tensor([-1.0665, -0.8581, -0.1699, -0.3978,  1.3480, -1.7216,  0.9590, -0.7473,
        -0.9275,  0.2192, -0.1230,  1.6407], requires_grad=True)
Weight L2 Norm:  10.454452514648438