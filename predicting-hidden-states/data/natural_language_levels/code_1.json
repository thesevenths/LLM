{
  "level": "code",
  "user": "Generate Python code",
  "assistant": "import music21\nimport music21.converter\nimport mido\nfrom collections import namedtuple\nimport numpy as np\n\nfrom symbolic_music.item_contextualizer import ItemContextualizer\n\nNoteEvent = namedtuple('NoteEvent', ['instrument', 'offset', 'offset_in_measure', 'pitch', 'velocity', 'duration'])\n\n\nclass DatasetCreator:\n    def __init__(self, instruments=[], time_resolution=0.01, velocity_resolution=1/32, num_pitches=128, offset_in_seconds=True, instrument_name_lookup=None):\n        pass\n        self.offset_in_seconds = offset_in_seconds\n        self.time_resolution = time_resolution\n        self.velocity_resolution = velocity_resolution\n        self.num_pitches = num_pitches\n        self.instruments = instruments\n        self.instrument_name_lookup = instrument_name_lookup\n        self.instrument_lookup = {inst: idx for idx, inst in enumerate(self.instruments)}\n        self.contextualizer = ItemContextualizer(num_instruments=len(self.instruments))\n\n    def get_part_names(self, parts):\n        part_names = []\n        if len(parts) != len(self.instruments):\n            print(\"wrong number of parts\")\n        for i, part in enumerate(parts):\n            name = part.partName\n            if name is None:\n                name = 'Undefined_' + str(i)\n            part_names.append(name)\n\n        # give parts unique names\n        new_part_names = []\n        for i, v in enumerate(part_names):\n            totalcount = part_names.count(v)\n            count = part_names[:i].count(v)\n            new_part_names.append(v + '_' + str(count + 1) if totalcount > 1 else v)\n        part_names = new_part_names\n\n        if self.instrument_name_lookup is not None:\n            for i, name in enumerate(part_names):\n                if name in self.instrument_name_lookup.keys():\n                    part_names[i] = self.instrument_name_lookup[name]\n                else:\n                    print('unknown part name:', name)\n        print('part names:', part_names)\n        return part_names\n\n    def parse_file(self, file, transposition=0):\n        stream = music21.converter.parseFile(file)\n        parts = list(stream.getElementsByClass('Part'))\n\n        if len(parts) != len(self.instruments):\n            print(\"wrong number of parts - skipping this file\")\n            return None\n\n        part_names = self.get_part_names(parts)\n\n        time_signatures = []\n        for ts in stream.getTimeSignatures():\n            time_signatures.append((ts.numerator, ts.denominator))\n\n        note_list = []\n        for i, part in enumerate(parts):\n            instrument = part_names[i]\n            element_map = part.flat.secondsMap\n            for element_dict in element_map:\n                element = element_dict['element']\n                if type(element) is not music21.note.Note:\n                    continue\n\n                measure_number = element.measureNumber\n                if measure_number is None:\n                    offset_in_measure = 0\n                else:\n                    measure = part.measure(measure_number)\n                    offset_in_measure = element.offset - measure.offset\n\n                if self.offset_in_seconds:\n                    offset = element_dict['offsetSeconds']\n                    duration = element_dict['durationSeconds']\n                else:\n                    offset = element.offset\n                    duration = element.duration.quarterLength\n                note = NoteEvent(instrument=instrument,\n                                  offset=offset,\n                                  offset_in_measure=offset_in_measure,\n                                  pitch=element.pitch.midi + transposition,\n                                  velocity=element.volume.realized,\n                                  duration=duration)\n                note_list.append(note)\n        note_list.sort(key=lambda n: n.offset)\n        return note_list\n\n    def parse_file_mido(self, file):\n        midi_file = mido.MidiFile(file)\n        meta_track = midi_file.tracks[0]\n        instrument_tracks = midi_file.tracks[1:]\n        ticks_per_beat = midi_file.ticks_per_beat\n        note_list = []\n\n        for track in instrument_tracks:\n            sustained_notes = []\n            instrument = track.name\n            if self.instrument_name_lookup is not None:\n                if instrument in self.instrument_name_lookup.keys():\n                    instrument = self.instrument_name_lookup[instrument]\n                else:\n                    print(\"unknown instrument name:\", instrument)\n            current_meta_track_index = 0\n            ticks_til_next_meta_msg = meta_track[0].time\n            current_time = 0\n            current_tempo = 500000\n            for msg in track:\n                if msg.time > ticks_til_next_meta_msg:\n                    current_time += (ticks_til_next_meta_msg / ticks_per_beat) * current_tempo * 1e-6\n                    ticks = msg.time - ticks_til_next_meta_msg\n                    ticks_til_next_meta_msg = 0\n                else:\n                    ticks = msg.time\n\n                while ticks_til_next_meta_msg <= 0:\n                    meta_msg = meta_track[current_meta_track_index]\n                    if meta_msg.type == 'set_tempo':\n                        current_tempo = meta_msg.tempo\n                    current_meta_track_index += 1\n                    if current_meta_track_index >= len(meta_track):\n                        ticks_til_next_meta_msg = 1e12\n                        break\n                    ticks_til_next_meta_msg += meta_track[current_meta_track_index].time\n\n                current_time += (ticks / ticks_per_beat) * current_tempo * 1e-6\n                ticks_til_next_meta_msg -= ticks\n\n                if msg.type == 'note_on' and msg.velocity > 0:\n                    if msg.velocity > 0:\n                        note = NoteEvent(instrument=instrument,\n                                         offset=current_time,\n                                         offset_in_measure=0,\n                                         pitch=msg.note,\n                                         velocity=msg.velocity/127,\n                                         duration=None)\n                        sustained_notes.append(note)\n                if msg.type == 'note_off' or hasattr(msg, 'velocity') and msg.velocity == 0:\n                    idx, note = next((i, n) for i, n in enumerate(sustained_notes) if n.pitch == msg.note)\n                    del sustained_notes[idx]\n                    duration = current_time - note.offset\n                    note_list.append(NoteEvent(instrument=note.instrument,\n                                               offset=note.offset,\n                                               offset_in_measure=note.offset_in_measure,\n                                               pitch=note.pitch,\n                                               velocity=note.velocity,\n                                               duration=duration))\n        note_list.sort(key=lambda n: n.offset)\n        return note_list\n\n    def discretize_note_list(self, note_list):\n        discretized_note = []\n        for note in note_list:\n            discretized_note.append(self.discretize_note(note))\n        return discretized_note\n\n    def discretize_note(self, note):\n        instrument = self.instrument_lookup[note.instrument]\n        offset = int(note.offset / self.time_resolution)\n        offset_in_measure = int(note.offset_in_measure / self.time_resolution)\n        velocity = int(note.velocity / self.velocity_resolution)\n        duration = int(note.duration / self.time_resolution)\n        disc_note = NoteEvent(instrument=instrument,\n                              offset=offset,\n                              offset_in_measure=offset_in_measure,\n                              pitch=note.pitch,\n                              velocity=velocity,\n                              duration=duration)\n        return disc_note\n\n    def commandify_note_list(self, note_list, max_wait=100):\n        on_off_commands = []\n        for note in note_list:\n            current_time = note.offset\n            # note on command\n            on_off_commands.append((current_time, 1, note.instrument, note.velocity, note.pitch, note.offset_in_measure))\n            # note off command\n            on_off_commands.append((current_time + note.duration, 0, note.instrument, note.pitch, note.offset_in_measure))\n\n        # sort by instrument\n        on_off_commands.sort(key=lambda n: n[2])\n        # sort by on/off (first all off events in this time step, then all on events)\n        on_off_commands.sort(key=lambda n: n[1])\n        # sort by time\n        on_off_commands.sort(key=lambda n: n[0])\n\n        command_items = []\n        current_time = 0\n        current_instrument = None\n        current_velocity = None\n\n        for oo_command in on_off_commands:\n            offset_in_measure = oo_command[-1]\n\n            # wait command\n            command_time = oo_command[0]\n            if command_time != current_time:\n                wait = command_time - current_time\n                while wait > max_wait:\n                    command_items.append([0, max_wait, offset_in_measure])\n                    wait -= max_wait\n                command_items.append([0, wait, offset_in_measure])\n                current_time = command_time\n\n            # instrument command\n            command_instrument = oo_command[2]\n            if command_instrument != current_instrument:\n                command_items.append([1, command_instrument, offset_in_measure])\n                current_instrument = command_instrument\n\n            if oo_command[1] == 1:  # if note on event\n                # velocity command\n                command_velocity = oo_command[3]\n                if command_velocity != current_velocity:\n                    command_items.append([2, command_velocity, offset_in_measure])\n                    current_velocity = command_velocity\n\n                # pitch command\n                command_pitch = oo_command[4]\n                command_items.append([3, command_pitch, offset_in_measure])\n            else:  # if note off event\n                # end command\n                command_pitch = oo_command[3]\n                command_items.append([4, command_pitch, offset_in_measure])\n\n        return np.int32(command_items)\n\n    def contextualize_commands(self, commands):\n        self.contextualizer.clear_context()\n        for command in commands:\n            self.contextualizer.add_item(command[np.newaxis, 0], command[np.newaxis, 1])\n        return self.contextualizer.current_context.astype(int)[0]\n\n    def get_all_part_names_from_path(self, path):\n        files = self.find_music_files(path)\n        for file in files:\n            print(file)\n            stream = music21.converter.parseFile(file)\n            parts = list(stream.getElementsByClass('Part'))\n            self.get_part_names(parts)\n\n    def create_contextualized_dataset(self, path, transpositions=[0], mode='music21'):\n        files = self.find_music_files(path)\n\n        data = {}\n        for transposition in transpositions:\n            for file_number, file in enumerate(files):\n                file_name = file.name\n                if transposition != 0:\n                    file_name = file_name + '_' + str(transposition)\n\n                print(\"process \" + str(file_number+1) + \"/\" + str(len(files)) + \": \" + file_name)\n\n                if mode == 'music21':\n                    note_list = self.parse_file(file, transposition=transposition)\n                elif mode == 'mido':\n                    note_list = self.parse_file_mido(file)\n                else:\n                    raise\n\n                print(\"number of notes:\", len(note_list))\n\n                if note_list is None:\n                    continue\n\n                try:\n                    discrete_note_list = self.discretize_note_list(note_list)\n                except KeyError:\n                    print(\"unknown instrument in\", file)\n                    continue\n                print(\"commandify\")\n                commands = self.commandify_note_list(discrete_note_list)\n                print(\"contextualize\")\n                context = self.contextualize_commands(commands)\n\n                data[file_name] = context\n\n        return {'data': data, 'meta_data': self.meta_data()}\n\n    def meta_data(self):\n        return {'instruments': self.instruments,\n                'num_pitches': self.num_pitches,\n                'time_resolution': self.time_resolution,\n                'velocity_resolution': self.velocity_resolution,\n                'num_wait': 100,\n                'num_velocities': 32}\n\n    @staticmethod\n    def find_music_files(path, types=['.xml', '.mxl', '.mid', '.midi']):\n        if not path.is_dir:\n            files = [path]\n        else:\n            files = []\n            for file_type in types:\n                files.extend(list(path.glob('**/*' + file_type)))\n                # files.extend(glob.glob(path + '/**/*' + file_type, recursive=True))\n        return files\n\n\n"
}