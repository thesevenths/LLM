{
  "level": "code",
  "user": "Generate Python code",
  "assistant": "from symbolic_music.note_event_dataset import NoteEventDataset\nfrom symbolic_music.itemized_note_dataset import ItemizedNoteDataset\nfrom symbolic_music.item_contextualizer import ItemContextualizer\n\nimport numpy as np\nimport pickle\n\nnote_event_dataset = NoteEventDataset()\nnote_event_dataset.load('/home/hev7rng/data/bach_chorales/bach_chorales_note_events_validation.p')\n\n#transpositions = [-3, -2, -1, 0, 1, 2, 3]\ntranspositions = [0]\nnew_data_dict = {}\nfor trans in transpositions:\n    for file, array in note_event_dataset.data.items():\n        new_array = np.copy(array)\n        new_array[:, 3] += trans\n        new_file = file + '_' + str(trans)\n        new_data_dict[new_file] = new_array\nnote_event_dataset.data = new_data_dict\n\nwait_dict = {i+1: i+1 for i in range(100)}\nitemized_dataset = ItemizedNoteDataset(note_event_dataset, wait_dict=wait_dict)\nitemized_dataset.calculate_reverse_lookups()\n\ncontextualizer = ItemContextualizer()\ncontextualized_pieces = {}\nfor piece, items in itemized_dataset.data.items():\n    print(\"contextualize\", piece)\n    contextualizer.clear_context()\n    for item in items:\n        contextualizer.add_item(item[np.newaxis, 0], item[np.newaxis, 1])\n    contextualized_pieces[piece] = contextualizer.current_context[0]\n\ndata_dict = {'data': contextualized_pieces, 'reverse_lookups': itemized_dataset.reverse_lookups}\nwith open('/home/hev7rng/data/bach_chorales/bach_chorales_contextualized_training_validation_new.p', 'wb') as handle:\n    pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
}