{
  "level": "code",
  "user": "Generate Python code",
  "assistant": "import mido\nimport torch\nimport torch.nn.functional as F\n\n\nclass MidiDataset:\n    def __init__(self, time_resolution=0.01, velocity_resolution=1/32, instrument_lookup=None,\n                 instrument_pitch_feature=True):\n        self.time_resolution = time_resolution\n        self.num_time_bins = int(1 / time_resolution)\n        self.num_pitches = 128\n        self.num_instruments = len(set(instrument_lookup.values())) if instrument_lookup is not None else 0\n        self.num_velocity_bins = int(1 / velocity_resolution)\n        self.instrument_pitch_feature = instrument_pitch_feature\n        self.velocity_resolution = velocity_resolution\n        self.instrument_lookup = instrument_lookup if instrument_lookup is not None else {}\n        self.calc_feature_sizes()\n\n    def calc_feature_sizes(self):\n        self.command_feature_sizes = torch.LongTensor([self.num_time_bins,       # wait\n                                                       self.num_pitches,         # note on\n                                                       self.num_pitches,         # note off\n                                                       self.num_instruments,     # change instrument\n                                                       self.num_velocity_bins,   # change velocity\n                                                       3])                       # buffer/start/end\n        self.command_feature_offset = torch.cumsum(torch.cat([torch.LongTensor([0]), self.command_feature_sizes]),\n                                                   dim=0)\n\n        if self.instrument_pitch_feature:\n            self.additional_feature_sizes = torch.LongTensor([self.num_instruments,  # current instrument\n                                                              self.num_pitches,      # current pitches\n                                                              self.num_pitches * self.num_instruments,  # current pitches in current instrument\n                                                              1,                     # current offset\n                                                              1,                     # current velocity\n                                                              1])                    # current positions\n        else:\n            self.additional_feature_sizes = torch.LongTensor([self.num_instruments,  # current instrument\n                                                              self.num_pitches,  # current pitches\n                                                              1,  # current offset\n                                                              1,  # current velocity\n                                                              1])  # current positions\n        \n        self.num_features = self.command_feature_offset[-1] + self.num_instruments + self.num_pitches + 3\n\n        if self.instrument_pitch_feature:\n            self.num_features += self.num_pitches\n\n    def create_on_off_wait_commands(self, path, ignore_tempo=False, ignore_velocity=False, tempo_factor=1.):\n        # convert a midi file into a 2d tensor of the form\n        # absolute_time       0    0    0    0    0   25   50   50\n        # command type      off  off   on   on   on wait  off  off\n        # command value      69   60   72   76   62   50   72   62\n        # instrument          1    0    1    1    0    -    1    0\n        # velocity            -    -   15   13   13    -    -    -\n\n        # wait command  note on command  note off command\n        #         time             time              time\n        #            0                1                 2\n        #       length            pitch             pitch\n        #           -1       instrument        instrument\n        #           -1         velocity                -1\n\n        # returns a tensor of the shape num_commands x 5\n\n        # read file\n        midi_file = mido.MidiFile(path)\n        meta_track = midi_file.tracks[0]\n        instrument_tracks = midi_file.tracks[1:]\n        ticks_per_beat = midi_file.ticks_per_beat\n\n        # update instrument_lookup:\n        # first search in the instrument_lookup, if there is no result, add a new ID\n        for i, t in enumerate(instrument_tracks):\n            instrument_name = t.name + '_' + str(i)\n            t.name = instrument_name\n            if not instrument_name in self.instrument_lookup.keys():\n                self.instrument_lookup[instrument_name] = len(self.instrument_lookup)\n        self.num_instruments = len(set(self.instrument_lookup.values()))\n        self.calc_feature_sizes()\n\n        # parse commands of all tracks with absolute time information\n        # using a list of note_on / note_off commands and their absolute time information\n        absolute_time_commands = []\n\n        for track in instrument_tracks:\n            instrument_id = self.instrument_lookup[track.name]\n            current_meta_track_index = 0\n            ticks_til_next_meta_msg = meta_track[0].time\n            current_time = 0\n            current_tempo = 500000\n\n            for msg in track:\n                # incorporate tempo change messages from the meta track\n                if msg.time > ticks_til_next_meta_msg:\n                    current_time += (ticks_til_next_meta_msg / ticks_per_beat) * current_tempo * 1e-6\n                    ticks = msg.time - ticks_til_next_meta_msg\n                    ticks_til_next_meta_msg = 0\n                else:\n                    ticks = msg.time\n\n                while ticks_til_next_meta_msg <= 0:\n                    meta_msg = meta_track[current_meta_track_index]\n                    if meta_msg.type == 'set_tempo':\n                        if not ignore_tempo:\n                            current_tempo = meta_msg.tempo\n                    current_meta_track_index += 1\n                    if current_meta_track_index >= len(meta_track):\n                        ticks_til_next_meta_msg = 1e12\n                        break\n                    ticks_til_next_meta_msg += meta_track[current_meta_track_index].time\n\n                current_time += (ticks / ticks_per_beat) * current_tempo * 1e-6\n                ticks_til_next_meta_msg -= ticks\n\n                if msg.type == 'note_on':\n                    if msg.velocity > 0:\n                        velocity = 0.5 if ignore_velocity else msg.velocity/127\n                        absolute_time_commands.append([current_time, 1, msg.note, instrument_id, velocity])\n                    else:\n                        absolute_time_commands.append([current_time, 2, msg.note, instrument_id, -1])\n                elif msg.type == 'note_off':\n                    absolute_time_commands.append([current_time, 2, msg.note, instrument_id, -1])\n\n        absolute_time_commands.sort(key=lambda i: i[2])  # sort by value\n        absolute_time_commands.sort(key=lambda i: i[3])  # sort by instrument\n        absolute_time_commands.sort(key=lambda i: i[1], reverse=True)  # sort by command type\n        absolute_time_commands.sort(key=lambda i: i[0])  # sort by time\n\n        # convert convert time information to wait commands and quantize time & velocity\n        on_off_wait_commands = []\n        current_time = absolute_time_commands[0][0]\n        quantized_time = 0\n        for command in absolute_time_commands:\n            command_time = command[0] / tempo_factor\n            if command_time - current_time > 0.001:\n                wait_time = int((command_time - current_time) / self.time_resolution)\n                # split long wait times into multiply wait commands\n                while wait_time > self.num_time_bins:\n                    on_off_wait_commands.append([quantized_time + self.num_time_bins // 2, 0, self.num_time_bins-1, -1, -1])\n                    wait_time -= self.num_time_bins\n                    quantized_time += self.num_time_bins\n                if wait_time > 0:\n                    on_off_wait_commands.append([quantized_time + wait_time // 2, 0, wait_time-1, -1, -1])\n                current_time = command_time\n            quantized_time = int(command_time / self.time_resolution)\n\n            if command[1] == 1:  # note on command\n                on_off_wait_commands.append([quantized_time] + command[1:4] + [int(command[4] / self.velocity_resolution)])\n            elif command[1] == 2:  # note off command\n                on_off_wait_commands.append([quantized_time] + command[1:])\n\n        on_off_wait_commands.sort(key=lambda i: i[2])  # sort by value\n        on_off_wait_commands.sort(key=lambda i: i[3])  # sort by instrument\n        on_off_wait_commands.sort(key=lambda i: i[1], reverse=True)  # sort by command type\n        on_off_wait_commands.sort(key=lambda i: i[0])  # sort by time\n\n        on_off_wait_tensor = torch.LongTensor(on_off_wait_commands)\n        return on_off_wait_tensor\n\n    def create_input_items(self, on_off_wait_tensor, shuffle=False, start_buffer=True, end_buffer=True, ignore_initial_velocity=False):\n        # on_off_wait_tensor: seq x [time, command type, command_value, instrument, velocity]\n\n        # return: seq x [command type, command value]\n\n        if shuffle:\n            on_off_wait_tensor = on_off_wait_tensor[torch.randperm(on_off_wait_tensor.shape[0])]\n            order = torch.sort(on_off_wait_tensor[:, 0])[1]\n            on_off_wait_tensor = on_off_wait_tensor[order]\n\n        # filter out unchanged instruments and velocities:\n        valid_instrument = on_off_wait_tensor[:, 3] >= 0\n        instrument_unchanged = (on_off_wait_tensor[valid_instrument, 3][1:] - on_off_wait_tensor[valid_instrument, 3][:-1]) == 0\n        instrument_unchanged = torch.cat([torch.BoolTensor([False]), instrument_unchanged])\n        valid_instrument[valid_instrument.clone()] = instrument_unchanged\n        on_off_wait_tensor[valid_instrument, 3] = -1\n\n        valid_velocity = on_off_wait_tensor[:, 4] >= 0\n        velocity_unchanged = (on_off_wait_tensor[valid_velocity, 4][1:] - on_off_wait_tensor[valid_velocity, 4][:-1]) == 0\n        if ignore_initial_velocity:\n            velocity_unchanged = torch.cat([torch.BoolTensor([True]), velocity_unchanged])\n        else:\n            velocity_unchanged = torch.cat([torch.BoolTensor([False]), velocity_unchanged])\n        valid_velocity[valid_velocity.clone()] = velocity_unchanged\n        on_off_wait_tensor[valid_velocity, 4] = -1\n\n        instrument_changes = torch.stack([torch.zeros(on_off_wait_tensor.shape[0], dtype=torch.long)+3,\n                                          on_off_wait_tensor[:, 3]], dim=1)\n        velocity_changes = torch.stack([torch.zeros(on_off_wait_tensor.shape[0], dtype=torch.long)+4,\n                                        on_off_wait_tensor[:, 4]], dim=1)\n        on_off_wait_commands = on_off_wait_tensor[:, 1:3]\n\n        item_tensor = torch.stack([instrument_changes, velocity_changes, on_off_wait_commands], dim=1).view(-1, 2)\n        item_tensor = item_tensor[item_tensor[:, 1] >= 0]\n        if start_buffer:\n            start_buffer = torch.LongTensor([[5, 0], [5, 1]])\n        else:\n            start_buffer = torch.zeros(0, 2, dtype=torch.long)\n        if end_buffer:\n            end_buffer = torch.LongTensor([[5, 2], [5, 0]])\n        else:\n            end_buffer = torch.zeros(0, 2, dtype=torch.long)\n        item_tensor = torch.cat([start_buffer, item_tensor, end_buffer], dim=0)\n        return item_tensor\n\n    @staticmethod\n    def transpose(on_off_wait_tensor, transposition=0):\n        if transposition != 0:\n            on_off_wait_tensor = on_off_wait_tensor.clone()\n            is_note_command = on_off_wait_tensor[:, 1] != 0\n            on_off_wait_tensor[is_note_command, 2] += transposition\n        return on_off_wait_tensor\n\n\n    def calculate_features(self, item_tensor, start_features=None, only_commands=False):\n        # features:\n        # command (one hot: num_time_bins + 2*num_pitches + num_instruments + num_velocity_bins + 3)\n        # current_instrument (one hot: num_instruments)\n        # current_pitches (multi hot: num_pitches)\n        # current_pitches in this instruments (multi hot: num_pitches * num_instruments)\n        # current_offset (one value)\n        # current_velocity (one value)\n        # current_position (one value)\n\n        # create command one hot vector\n        command_value = self.command_feature_offset[item_tensor[:, 0]] + item_tensor[:, 1]\n        one_hot_command = F.one_hot(command_value, num_classes=self.command_feature_offset[-1])\n\n        if only_commands:\n            return one_hot_command, command_value\n\n        if start_features is not None:\n            additional_features = torch.split(start_features[None], self.additional_feature_sizes.tolist(), dim=1)\n        else:\n            additional_features = [torch.zeros(1, n, dtype=torch.long) for n in self.additional_feature_sizes]\n\n        if self.instrument_pitch_feature:\n            c_instrument, c_pitches, c_instrument_pitches, c_offset, c_velocity, c_position = additional_features\n            c_instrument_pitches = c_instrument_pitches.view(self.num_instruments, self.num_pitches)\n        else:\n            c_instrument, c_pitches, c_offset, c_velocity, c_position = additional_features\n\n        # current_instrument: command ID 3\n        if torch.sum(c_instrument) > 0:\n            c_instrument_idx = torch.argmax(c_instrument).view(1)\n        else:\n            c_instrument_idx = torch.LongTensor([0])\n        instrument_change_indices = item_tensor[:, 0] == 3\n        instrument_changes = item_tensor[instrument_change_indices, 1]\n        instrument_changes_diff = instrument_changes - torch.cat([c_instrument_idx, instrument_changes[:-1]])\n        instrument_changes_filled = torch.zeros_like(item_tensor[:, 0])\n        instrument_changes_filled[instrument_change_indices] = instrument_changes_diff\n        current_instrument_idx = torch.cumsum(instrument_changes_filled, dim=0)\n        current_instrument_idx += c_instrument_idx[0]\n        current_instrument = F.one_hot(current_instrument_idx, num_classes=self.num_instruments)\n\n        # current_pitches: command IDs 1&2\n        note_on_indices = item_tensor[:, 0] == 1\n        note_off_indices = item_tensor[:, 0] == 2\n        note_on_changes = F.one_hot(item_tensor[note_on_indices, 1], num_classes=self.num_pitches)\n        note_off_changes = F.one_hot(item_tensor[note_off_indices, 1], num_classes=self.num_pitches)\n        if self.instrument_pitch_feature:\n            note_on_filled = torch.zeros(item_tensor.shape[0], self.num_instruments, self.num_pitches, dtype=torch.long)\n            note_off_filled = torch.zeros(item_tensor.shape[0], self.num_instruments, self.num_pitches, dtype=torch.long)\n            note_on_filled[note_on_indices] += note_on_changes[:, None].repeat(1, self.num_instruments, 1)\n            note_off_filled[note_off_indices] += note_off_changes[:, None].repeat(1, self.num_instruments, 1)\n            inactive_instruments = (1 - current_instrument).bool()\n            note_on_filled[inactive_instruments, :] = 0\n            note_off_filled[inactive_instruments, :] = 0\n            #note_on_filled[0] += c_instrument_pitches\n            note_on_filled = torch.cumsum(note_on_filled, dim=0)\n            note_off_filled = torch.cumsum(note_off_filled, dim=0)\n            current_pitches_per_instrument = note_on_filled - note_off_filled\n            current_pitches_per_instrument += c_instrument_pitches[0]\n            current_instrument_pitches = current_pitches_per_instrument[current_instrument.bool(), :]\n            current_pitches = current_pitches_per_instrument.sum(dim=1)\n        else:\n            note_on_filled = torch.zeros(item_tensor.shape[0], self.num_pitches, dtype=torch.long)\n            note_off_filled = torch.zeros(item_tensor.shape[0], self.num_pitches, dtype=torch.long)\n            note_on_filled[note_on_indices] = note_on_changes\n            note_off_filled[note_off_indices] = note_off_changes\n            #note_on_filled[0] += c_pitches[0]\n            note_on_filled = torch.cumsum(note_on_filled, dim=0)\n            note_off_filled = torch.cumsum(note_off_filled, dim=0)\n            current_pitches = note_on_filled - note_off_filled\n            current_pitches += c_pitches[0]\n\n        # current_offset: command ID 0\n        wait_indices = item_tensor[:, 0] == 0\n        wait_values = item_tensor[wait_indices, 1]\n        offset_filled = torch.zeros_like(item_tensor[:, 0])\n        offset_filled[wait_indices] = wait_values+1\n        offset_filled = torch.cumsum(offset_filled, dim=0)\n        offset_filled = torch.cat([torch.LongTensor([0]), offset_filled], dim=0)\n        offset_filled += c_offset[0]\n        current_offset = offset_filled[:-1][:, None]\n\n        # current_velocity: command ID 4\n        velocity_indices = item_tensor[:, 0] == 4\n        velocity_changes = item_tensor[velocity_indices, 1]\n        velocity_changes_diff = velocity_changes - torch.cat([c_velocity.view(1), velocity_changes[:-1]])\n        velocity_changes_filled = torch.zeros_like(item_tensor[:, 0])\n        velocity_changes_filled[velocity_indices] = velocity_changes_diff\n        current_velocity = torch.cumsum(velocity_changes_filled, dim=0)[:, None]\n        current_velocity += c_velocity[0]\n\n        # current_position\n        current_position = torch.arange(item_tensor.shape[0])[:, None]\n\n        if self.instrument_pitch_feature:\n            features = torch.cat([one_hot_command,\n                                  current_instrument,\n                                  current_pitches,\n                                  current_instrument_pitches,\n                                  current_offset,\n                                  current_velocity,\n                                  current_position], dim=1)\n        else:\n            features = torch.cat([one_hot_command,\n                                  current_instrument,\n                                  current_pitches,\n                                  current_offset,\n                                  current_velocity,\n                                  current_position], dim=1)\n        return features, command_value\n\n    def index_to_item(self, idx):\n        # with batch dimension\n        values = idx[:, None] - self.command_feature_offset[None, :-1]\n        item_types = torch.arange(0, 5)[None, :].repeat(idx.shape[0], 1)\n        a = values >= 0\n        b = self.item_value_offsets[None, 1:] - idx[:, None] > 0\n        value = values[a * b]\n        item_type = item_types[a * b]\n        return item_type, value\n\n    def midifile_from_item_tensor(self, item_tensor, ticks_per_second=256, tempo=1000000):\n        features, command_value = self.calculate_features(item_tensor)\n        context_features = features[:, self.command_feature_offset[-1]:]\n        instrument, pitches, offset, velocity, position = torch.split(context_features,\n                                                                      self.additional_feature_sizes.tolist(),\n                                                                      dim=1)\n        # guess tempo\n        # wait_command_values = item_tensor[item_tensor[:, 0] == 0, 1]\n        # TODO\n\n        midifile = mido.MidiFile()\n        meta_track = mido.MidiTrack()\n        meta_track.append(mido.MetaMessage('set_tempo', tempo=tempo))\n        midifile.tracks.append(meta_track)\n        midifile.ticks_per_beat = ticks_per_second\n\n        tracks = [mido.MidiTrack() for _ in range(self.num_instruments)]\n        tracks_last_tick = [0 for _ in range(self.num_instruments)]\n        tracks_note_on_has_happened = [False for _ in range(self.num_instruments)]  # to filter out note off messages at the start\n\n        for i in range(item_tensor.shape[0]):\n            [item_type, item_value] = item_tensor[i]\n            if item_type == 1 or item_type == 2:  # note_on or note_off\n                item_instrument = torch.argmax(instrument[i]).item()\n                item_offset = offset[i].item()\n                item_velocity = int(float(velocity[i]) * self.velocity_resolution * 127.)\n\n                item_absolute_ticks = int(float(item_offset) * self.time_resolution * ticks_per_second)\n                item_time = max(0, item_absolute_ticks - tracks_last_tick[item_instrument])\n\n                if item_type == 1:\n                    tracks_last_tick[item_instrument] = item_absolute_ticks\n                    tracks[item_instrument].append(mido.Message('note_on',\n                                                                channel=item_instrument,\n                                                                note=item_value.item(),\n                                                                velocity=item_velocity,\n                                                                time=item_time))\n                    tracks_note_on_has_happened[item_instrument] = True\n                elif item_type == 2:\n                    if tracks_note_on_has_happened[item_instrument]:\n                        tracks_last_tick[item_instrument] = item_absolute_ticks\n                        tracks[item_instrument].append(mido.Message('note_off',\n                                                                    channel=item_instrument,\n                                                                    note=item_value.item(),\n                                                                    velocity=0,\n                                                                    time=item_time))\n                    else:\n                        print(\"note off event before any note has been played\")\n        midifile.tracks.extend(tracks)\n        return midifile\n\n\n\n\n"
}